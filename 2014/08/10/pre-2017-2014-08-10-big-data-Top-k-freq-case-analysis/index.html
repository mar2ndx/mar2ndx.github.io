<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
  <title>
    
    [Design] Big Data - Top k Frequency (case analysis) 丨
    

    typo
  </title>

  
  <link rel="shortcut icon" href="/icon.svg">
  

  <link rel="preconnect" href="https://cdnjs.cloudflare.com">
  
  <link id="theme" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-light.css">
  <script src="https://unpkg.com/@highlightjs/cdn-assets@11.9.0/highlight.min.js"></script>
  

  <!-- 字体 -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap" rel="stylesheet">

  
<link rel="stylesheet" href="/css/root.css">

  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/css/post.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <header class="header">
  <section class="header-container">
    <a class="logo" href="/">Tech blog</a>
    <ul class="nav">
      
      <li><a href="/archives">archives</a></li>
      
      <li><a href="/about">about</a></li>
      
    </ul>
  </section>
</header>
  <main class="main">
    <article class="post">
  
  <div class="post-title">[Design] Big Data - Top k Frequency (case analysis)</div>
  <div class="post-meta">
    <div class="date">2014 August 10th</div>
    <div class="tags">
      
    </div>
  </div>
  

  <main class="post-content"><h3 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h3><p><a target="_blank" rel="noopener" href="http://dongxicheng.org/big-data/select-ten-from-billions/">link</a></p>
<blockquote>
<p>在海量数据中找出出现频率最高的前 K 个数，或者从海量数据中找出最大的前 K 个数，这类问题通常称为“top K”问题，</p>
</blockquote>
<blockquote>
<ol>
<li>top K value</li>
<li>top K frequency</li>
</ol>
</blockquote>
<h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><p><strong>Standard solution</strong> is 【分治+trie 树&#x2F;hash+小顶堆&#x2F;quickselect】, which I covered in another post <a href="/design/2014-07-25-big-data-Top-k-frequency">Big Data - Top k Frequency</a>. Briefly it is 3 steps:</p>
<ol>
<li>先将数据集按照 hash 方法分解成多个小数据集，</li>
<li>使用 trie 树或者 hash 统计每个小数据集中的 query 词频，</li>
<li>用小顶堆&#x2F;quickselect 求出每个数据集中出频率最高的前 K 个数</li>
</ol>
<p>But, there’re other senarios where different solutions may apply. Consider:</p>
<ol>
<li><p>Single core vs. multiple core</p>
</li>
<li><p>Single PC vs. multiple PC</p>
</li>
<li><p>Large RAM vs. limited RAM</p>
</li>
<li><p>Distributed system</p>
</li>
</ol>
<h3 id="1-单机-单核-足够大内存"><a href="#1-单机-单核-足够大内存" class="headerlink" title="1. 单机+单核+足够大内存"></a>1. 单机+单核+足够大内存</h3><p>设每个查询词平均占 8Byte，则 10 亿个查询词所需的内存大约是 10^9*8&#x3D;8G 内存。如果你有这么大的内存，直接在内存中对查询词进行排序，顺序遍历找出 10 个出现频率最大的 10 个即可。这种方法简单快速，更加实用。当然，也可以先用 HashMap 求出每个词出现的频率，然后求出出现频率最大的 10 个词。</p>
<h3 id="2-单机-单核-受限内存"><a href="#2-单机-单核-受限内存" class="headerlink" title="2. 单机+单核+受限内存"></a>2. 单机+单核+受限内存</h3><p>这种情况下，需要将原数据文件切割成一个一个小文件，如，采用 hash(x)%M，将原文件中的数据切割成 M 小文件，如果小文件仍大于内存大小，继续采用 hash 的方法对数据文件进行切割，直到每个小文件小于内存大小，这样，每个文件可放到内存中处理。采用 3.1 节的方法依次处理每个小文件。</p>
<h3 id="3-单机-多核-足够大内存"><a href="#3-单机-多核-足够大内存" class="headerlink" title="3. 单机+多核+足够大内存"></a>3. 单机+多核+足够大内存</h3><p>这时可以直接在内存中实用 hash 方法将数据划分成 n 个 partition，每个 partition 交给一个线程处理，线程的处理逻辑是同[1]节类似，最后一个线程将结果归并。</p>
<p>该方法存在一个瓶颈会明显影响效率，即数据倾斜，每个线程的处理速度可能不同，快的线程需要等待慢的线程，最终的处理速度取决于慢的线程。解决方法是，<strong>将数据划分成 (c x n)个 partition（c&gt;1），每个线程处理完当前 partition 后主动取下一个 partition 继续处理</strong>，直到所有数据处理完毕，最后由一个线程进行归并。</p>
<h3 id="4-多机-受限内存"><a href="#4-多机-受限内存" class="headerlink" title="4. 多机+受限内存"></a>4. 多机+受限内存</h3><p>这种情况下，为了合理利用多台机器的资源，可将数据分发到多台机器上，每台机器采用[3]节中的策略解决本地的数据。可采用<strong>hash + socket</strong>方法进行数据分发。</p>
<h3 id="5-Distributed"><a href="#5-Distributed" class="headerlink" title="5. Distributed"></a>5. Distributed</h3><p>Top k 问题很适合采用<strong>MapReduce 框架</strong>解决，用户只需编写一个 map 函数和两个 reduce 函数，然后提交到 Hadoop（采用 mapchain 和 reducechain）上即可解决该问题。</p>
<p>A map function. 对于 map 函数，采用 hash 算法，将 hash 值相同的数据交给同一个 reduce task.</p>
<p>2 reduce functions. 对于<strong>第一个 reduce 函数</strong>，采用 HashMap 统计出每个词出现的频率，对于<strong>第二个 reduce 函数</strong>，统计所有 reduce task 输出数据中的 top k 即可。</p>
<h3 id="6-Other"><a href="#6-Other" class="headerlink" title="6. Other"></a>6. Other</h3><p>公司一般不会自己写个程序进行计算，而是提交到自己核心的数据处理平台上计算，该平台的计算效率可能不如直接写程序高，但它具有<strong>良好的扩展性和容错性</strong>，而这才是企业最看重的。</p>
</main>

</article>


<script src="/js/highlight.js"></script>

  </main>
  <footer class="footer">
  
  <span>Copyright © 2024 typo</span>
  
</footer>
  
<script src="/js/theme.js"></script>

</body>

</html>